1Ô∏è‚É£ Principio rector (esto lo fija todo)

En K9, los hechos no se interpretan dos veces,
las decisiones no se recalculan,
y la narrativa nunca inventa.

Traducci√≥n t√©cnica:

Hechos ‚Üí OperationalAnalysis

Juicio ‚Üí Analyst

Comunicaci√≥n ‚Üí Narrative

2Ô∏è‚É£ Redefinici√≥n clara de cada nodo (sin cambiar nombres)
üü¶ DataEngineNode ‚Äî Fuente √∫nica de datos

No cambia. Est√° bien.

Responsabilidad:

Cargar STDE completo

Normalizar estructura

No interpretar

Salida esperada:

engine = {
  "stde": {...},
  "observations": [...],
  "audits": [...],
  "fdo": {...},
  "proactive": {...}
}

üü© OperationalAnalysisNode ‚Äî Capa de evidencia (CR√çTICO)

üëâ Este es el nodo clave que hoy no est√° completamente aprovechado.

Responsabilidad REAL

Convertir datos crudos en hechos operacionales verificables

Salida obligatoria y estable
analysis["operational_analysis"] = {
    "evidence_by_risk": {
        "R01": {
            "occ_count": int,
            "opg_count": int,
            "weekly_trend": "increasing|stable|decreasing",
            "signals_before_critical_monday": bool
        }
    },
    "temporal_signals": {
        "critical_monday": True,
        "weeks_analyzed": int
    },
    "pressure_by_risk": {
        "R01": float,
        "R02": float
    }
}


üìå Regla inquebrantable

Nada de esto se borra ni se reemplaza despu√©s.

üü® AnalystNode ‚Äî Juicio y decisi√≥n (NO hechos)

El Analyst NO responde preguntas, NO cuenta cosas, NO describe eventos.

Responsabilidad

Tomar evidencia ‚Üí emitir juicio

Salida:

analysis["risk_summary"] = {
    "dominant_risk": "R02",
    "relevant_risks": ["R01"]
}

analysis["proactive_comparison"] = {
    "R01": {"alignment_status": "underestimated_by_proactive"},
    "R02": {"alignment_status": "aligned"}
}

analysis["preventive_decision"] = {...}


üìå El Analyst nunca debe ocultar evidencia

üüß MetricsNode + Adapter ‚Äî Visualizaci√≥n, no narrativa

Aqu√≠ aclaro la confusi√≥n:

¬øPara qu√© sirven?

Tablas

Rankings

Gr√°ficos

Dashboards

¬øPara qu√© NO sirven?

No explican

No narran

No reemplazan texto

üëâ Son salida paralela, no insumo narrativo

üü• NarrativeNode ‚Äî Comunicaci√≥n consciente

Aqu√≠ va la mejora fuerte, sin romper lo bueno.

Regla de oro

El NarrativeNode elige qu√© decir,
pero nunca deduce lo que no existe.

üß† Nuevo orden interno del NarrativeNode
1Ô∏è‚É£ Preguntas de HECHOS

Ejemplos:

‚Äú¬øQu√© se√±ales aparecieron antes del lunes cr√≠tico?‚Äù

‚Äú¬øCu√°ntas observaciones hubo?‚Äù

‚Äú¬øQu√© pas√≥ la semana pasada?‚Äù

‚û°Ô∏è Fuente √∫nica: operational_analysis

2Ô∏è‚É£ Preguntas de JUICIO

Ejemplos:

‚Äú¬øCu√°l es el riesgo m√°s importante?‚Äù

‚Äú¬øEst√° subestimado por el proactivo?‚Äù

‚û°Ô∏è Fuente: risk_summary, proactive_comparison

3Ô∏è‚É£ Preguntas MIXTAS

Ejemplo:

‚Äú¬øPor qu√© el proactivo no refleja R01?‚Äù

‚û°Ô∏è Hechos + Juicio

evidence_by_risk[R01]

alignment_status[R01]

4Ô∏è‚É£ Fallback honesto (ESTA PARTE ESTABA BIEN)

Solo cuando:

No hay evidencia

No hay juicio

No hay intenci√≥n clara

----------------

1) Lenguaje del sistema: K9 Commands (can√≥nico, estable)
1.1. Estructura m√≠nima del comando

Usa un string √∫nico y parseable (sin LLM):

Prefijo: K9/1.0

Acci√≥n: GET, EXPLAIN, LIST

Recurso: RISK, EVENTS, OBS, AUDITS, FDO, PROACTIVE, SUMMARY

Filtros: week, risk_id, type, limit, etc.

Ejemplos:

K9/1.0 GET SUMMARY week=12

K9/1.0 LIST EVENTS week=1

K9/1.0 LIST OBS week=12

K9/1.0 GET RISK risk_id=R02 horizon=weekly

K9/1.0 EXPLAIN PROACTIVE_DIFF risk_id=R01

K9/1.0 GET SIGNALS before=critical_monday

Esto reemplaza (por ahora) el ‚Äúintent_classifier por keywords‚Äù.

1.2. Detecci√≥n de modo ‚Äúcomando‚Äù

Sin LLM:

Si user_query empieza con K9/ ‚Üí intent = "system_command"

Si no ‚Üí intent = "natural_language" (y por ahora va a fallback controlado o demo_mode)

2) Qu√© debe responder cada capa

Aqu√≠ est√° la parte clave: el sistema debe ‚Äúentender‚Äù cu√°ndo usar Operational vs Analyst no por lenguaje natural, sino por el tipo de comando.

2.1. OperationalAnalysisNode = ‚ÄúHechos consultables‚Äù

Debe exponer (no solo resumir) √≠ndices para responder preguntas tipo:

‚Äúdame los eventos de la semana 1‚Äù

‚Äúdame observaciones semana 12‚Äù

‚Äúcu√°ntas OCC/OPG por riesgo en semana X‚Äù

‚Äúse√±ales antes de lunes cr√≠tico‚Äù (si est√° modelado)

Salida requerida (contrato)

En analysis["operational"]:

analysis["operational"] = {
  "indexes": {
    "events_by_week": { 1: [...], 2: [...], ... },
    "obs_by_week": { 1: [...], ... },
    "audits_by_week": { ... },
  },
  "counts": {
    "obs_counts_by_week": { 12: {"OPG": 34, "OCC": 8, "TOTAL": 42}, ... },
    "obs_counts_by_risk": { "R01": {"OPG": x, "OCC": y}, ... },
    "events_counts_by_week": { ... },
  },
  "signals": {
    "critical_monday": {
      "exists": True,
      "week": 12,
      "summary": "‚Ä¶"
    },
    "before_critical_monday": {
      "weeks": [10,11,12],
      "by_risk": {
         "R01": {"OPG":..., "OCC":..., "events":...},
      }
    }
  },
  "traceability": [...]
}


Con esto, LIST EVENTS week=1 es trivial: el narrative solo formatea.

2.2. AnalystNode = ‚ÄúJuicio / decisi√≥n‚Äù

Debe consumir analysis["operational"] y producir:

risk_summary

proactive_comparison

preventive_decision

(opcional) pressure_assessment

Pero no debe ser el lugar donde se ‚Äúbuscan eventos‚Äù.

2.3. NarrativeNode = ‚ÄúRenderer‚Äù

Narrative no decide ‚Äúqu√© calcular‚Äù. Decide ‚Äúqu√© decir‚Äù seg√∫n:

el comando recibido (si existe)

los campos presentes en analysis

Narrative debe seguir esta jerarqu√≠a:

Si intent == system_command ‚Üí route por command.resource

Si no, sin LLM a√∫n ‚Üí respuesta controlada (explica que se requieren comandos o activa modo demo)

3) Router real (sin LLM): en base al comando, no a keywords

Agregar un parser m√≠nimo:

parsed = {
  "version": "K9/1.0",
  "action": "LIST",
  "resource": "EVENTS",
  "filters": {"week": 1}
}
state.command = parsed


Luego el router:

resource in ["EVENTS","OBS","AUDITS","FDO"] ‚Üí exige analysis["operational"] (facts)

resource in ["SUMMARY","RISK","SIGNALS"] ‚Üí usa operational + analyst

resource in ["PROACTIVE_DIFF","EXPLAIN"] ‚Üí usa analyst + operational

4) Smoke tests correctos para esta etapa

El smoke ahora debe ser una bater√≠a de comandos can√≥nicos, no lenguaje natural.

4.1. Ejemplos de smoke ‚Äúfase sin LLM‚Äù

Riesgo dominante semana 12

Q: K9/1.0 GET SUMMARY week=12

Must contain: R02 (y tokens estructurales: ‚Äúdominante‚Äù o ‚Äúrisk_summary‚Äù)

Subestimaci√≥n proactivo para R01

Q: K9/1.0 EXPLAIN PROACTIVE_DIFF risk_id=R01

Must contain: R01 y proactivo y alignment o subestim

Se√±ales antes de lunes cr√≠tico

Q: K9/1.0 GET SIGNALS before=critical_monday

Must contain: lunes o critical y al menos un riesgo

Observaciones semana 12

Q: K9/1.0 GET OBS_COUNTS week=12

Must contain: OPG OCC y TOTAL (o valores)

Eventos semana 1 (tu caso)

Q: K9/1.0 LIST EVENTS week=1

Must satisfy: respuesta no vac√≠a o ‚Äúno hay eventos registrados en semana 1‚Äù (pero basado en data real, no invento)

4.2. Qu√© valida realmente

Los nodos generan los campos correctos

El router selecciona bien

El narrative sabe ‚Äúrenderizar‚Äù facts vs juicio

No dependes de NLP

5) Luego: set amplio de comandos can√≥nicos para el LLM

Cuando integras el LLM, su trabajo es:

Convertir pregunta natural ‚Üí comando can√≥nico + filtros

Ejecutar el grafo

Convertir salida (analysis, metrics, reasoning) ‚Üí respuesta natural

Ejemplos de mapeo LLM

‚ÄúDame los eventos de la semana 1‚Äù ‚Üí K9/1.0 LIST EVENTS week=1

‚Äú¬øQu√© se√±ales antes del lunes cr√≠tico?‚Äù ‚Üí K9/1.0 GET SIGNALS before=critical_monday

‚Äú¬øQu√© riesgo es dominante y por qu√©?‚Äù ‚Üí K9/1.0 GET SUMMARY week=current + K9/1.0 EXPLAIN WHY dominant

6) Qu√© hay que mejorar ahora (concreto)
A) OperationalAnalysisNode (prioridad 1)

Crear √≠ndices *_by_week

Crear counts obs_counts_by_week

Exponer events (si existen en engine; si no, crear contenedor vac√≠o coherente)

Exponer signals.before_critical_monday

Objetivo: que cualquier consulta factual tenga respuesta determinista sin LLM.

B) AnalystNode (prioridad 2)

Debe usar operational para justificar

Debe producir proactive_comparison por riesgo siempre (aunque sea ‚Äúinsufficient_evidence‚Äù)

C) NarrativeNode (prioridad 3)

Implementar ‚Äúrender por comando‚Äù

No inventar

Si el comando pide algo que no existe ‚Üí respuesta honesta: ‚Äúno hay registros / no hay evidencia‚Äù y reasoning claro.

D) Smoke (prioridad 4)

Reescribir smoke_k9_full.py para ejecutar comandos K9/1.0 ...

Validar contratos (tokens + estructura), no frases humanas

Siguiente paso recomendado (sin preguntas, directo)

Si me adjuntas estos 3 archivos actuales del repo (los reales, no versiones sueltas):

src/nodes/operational_analysis_node.py (o el nombre real)

src/nodes/analyst_node.py

src/nodes/narrative_node.py

y el smoke/smoke_k9_full.py

------------------

Tienes raz√≥n: operational y analyst deben quedar blindados para cualquier pregunta sobre data sint√©tica, incluidas fechas reales (‚Äúprimera semana de enero‚Äù), no solo semanas indexadas.
Pero esa capacidad NO se logra en el narrative, ni en el intent, ni en el smoke en lenguaje natural.

Se logra definiendo correctamente el contrato temporal del sistema cognitivo.

Voy por partes, con precisi√≥n.

1Ô∏è‚É£ El error conceptual que nos estaba atrapando

Est√°bamos intentando que el sistema:

entienda lenguaje natural

resuelva ambig√ºedad temporal (‚Äúprimera semana de enero‚Äù)

decida si usar operational o analyst

y responda bien

sin LLM, usando intents por keywords.

üëâ Eso no es posible ni deseable.

El sistema cognitivo NO debe entender lenguaje humano.
Debe entender lenguaje temporal can√≥nico.

El LLM vendr√° despu√©s a traducir.

2Ô∏è‚É£ Principio rector (muy importante)

Operational y Analyst deben ser ciegos al lenguaje humano.
Solo deben operar sobre:

identificadores can√≥nicos

rangos temporales normalizados

estructuras expl√≠citas

Si una pregunta dice:

‚Äúqu√© eventos pasaron la primera semana de enero‚Äù

Eso NO es una pregunta v√°lida para el sistema interno.

Debe convertirse primero en algo como:

K9/1.0 LIST EVENTS date_range=2025-01-01..2025-01-07


O, si tu data es semanal:

K9/1.0 LIST EVENTS week_id=2025-W01

3Ô∏è‚É£ Entonces, ¬øc√≥mo blindamos operational y analyst?
üîí Blindaje real = modelo temporal expl√≠cito

La data sint√©tica DEBE tener un modelo temporal formal.
Uno (o ambos) de estos:

Opci√≥n A ‚Äî Modelo semanal (recomendado para K9 demo)
event = {
  "event_id": "...",
  "week_id": "2025-W01",
  "week_index": 1,
  "risk_id": "R01",
  "date_anchor": "2025-01-01",  # opcional
}

Opci√≥n B ‚Äî Modelo por fecha (si ya existe)
event = {
  "event_id": "...",
  "date": "2025-01-03",
  "week_id": "2025-W01",
  "risk_id": "R01",
}


üëâ Operational trabaja SIEMPRE con week_id / date_range, nunca con frases humanas.

4Ô∏è‚É£ Qu√© debe exponer el OperationalAnalysisNode (blindado)

Este es el n√∫cleo.

üì¶ Contract obligatorio de analysis["operational"]
analysis["operational"] = {
  "calendar": {
    "weeks": {
      "2025-W01": {
        "start": "2025-01-01",
        "end": "2025-01-07",
        "index": 1,
        "label": "Primera semana de enero"
      },
      ...
    }
  },

  "events": {
    "by_week": {
      "2025-W01": [event1, event2],
      ...
    }
  },

  "observations": {
    "by_week": {
      "2025-W01": {
        "OPG": [...],
        "OCC": [...]
      }
    }
  },

  "counts": {
    "events_by_week": {
      "2025-W01": 3
    },
    "observations_by_week": {
      "2025-W01": {
        "OPG": 12,
        "OCC": 4,
        "TOTAL": 16
      }
    }
  },

  "signals": {
    "critical_monday": {
      "week_id": "2025-W12"
    },
    "before_critical_monday": {
      "weeks": ["2025-W10", "2025-W11"],
      "evidence": {...}
    }
  }
}


üëâ Con esto, cualquier pregunta factual es respondible, siempre que venga en forma can√≥nica.

5Ô∏è‚É£ Rol correcto del AnalystNode (y qu√© NO debe hacer)
Analyst S√ç debe:

evaluar tendencias

comparar proactivo vs K9

decidir riesgo dominante

generar juicios (‚Äúemergente‚Äù, ‚Äúsubestimado‚Äù)

Analyst NO debe:

buscar eventos por fecha

contar observaciones crudas

interpretar lenguaje natural

Ejemplo v√°lido:

K9/1.0 EXPLAIN RISK risk_id=R01 horizon=monthly


Ejemplo inv√°lido para analyst:

‚Äúqu√© pas√≥ la primera semana de enero‚Äù

Eso es operational puro.

6Ô∏è‚É£ NarrativeNode: renderer, no cerebro

Ahora queda claro por qu√© el narrative fallaba.

El narrative no puede inventar ‚Äúlunes‚Äù, ‚Äúenero‚Äù, ‚Äúsemana‚Äù
si nadie se lo entreg√≥ expl√≠citamente.

Narrative debe hacer solo esto:

Si el comando es LIST EVENTS week_id=2025-W01

Renderiza la lista o dice ‚Äúno hay eventos‚Äù

Si el comando es GET SUMMARY

Usa risk_summary

Si el comando es GET SIGNALS before=critical_monday

Usa operational.signals.before_critical_monday

üëâ Nunca inferir fechas
üëâ Nunca interpretar lenguaje humano

7Ô∏è‚É£ El smoke correcto (clave de todo)

El smoke que estaban usando no puede funcionar sin LLM.
El smoke correcto no usa espa√±ol natural.

Ejemplo de smoke correcto (pre-LLM)
run_smoke(
  "K9/1.0 LIST EVENTS week_id=2025-W01",
  must_contain=["2025-W01"]
)

run_smoke(
  "K9/1.0 GET OBS_COUNTS week_id=2025-W12",
  must_contain=["OPG", "OCC"]
)

run_smoke(
  "K9/1.0 GET SIGNALS before=critical_monday",
  must_contain=["critical"]
)

Lo que NO se debe testear a√∫n:

‚Äú¬øqu√© pas√≥ en enero?‚Äù

‚Äú¬øqu√© se√±ales hubo antes del lunes cr√≠tico?‚Äù

Eso es trabajo del LLM, no del core.

8Ô∏è‚É£ Flujo final correcto (muy importante)
Usuario (lenguaje natural)
        ‚Üì
LLM (traductor sem√°ntico)
        ‚Üì
K9 Command (can√≥nico, temporal)
        ‚Üì
Operational / Analyst (blindados)
        ‚Üì
Narrative (render)
        ‚Üì
LLM (re-expresi√≥n humana)

---------------------------

1Ô∏è‚É£ Principio base (no negociable)

Operational y Analyst NO responden preguntas.
Ejecutan comandos cognitivos sobre un estado estructurado.

Por lo tanto, lo primero que definimos no son ‚Äúpreguntas‚Äù, sino:

üëâ QUERIES COGNITIVAS CAN√ìNICAS

2Ô∏è‚É£ Tipos de consultas que el sistema DEBE poder responder

Si miras todas las preguntas posibles (incluidas las que a√∫n no hicimos), se reducen a 6 familias fundamentales:

A. Consultas FACTUALES (Operational puras)

üëâ ‚ÄúQu√© pas√≥‚Äù
üëâ ‚ÄúCu√°ntos hubo‚Äù
üëâ ‚ÄúCu√°ndo ocurri√≥‚Äù

Ejemplos humanos:

‚ÄúDame los eventos de la semana 1‚Äù

‚ÄúCu√°ntas observaciones hubo‚Äù

‚ÄúQu√© eventos pasaron antes del lunes cr√≠tico‚Äù

üîë Esto es 100% Operational
B. Consultas TEMPORALES (Operational)

üëâ ‚ÄúEn qu√© periodo‚Äù
üëâ ‚ÄúAntes / despu√©s de‚Äù

Ejemplos humanos:

‚ÄúPrimera semana de enero‚Äù

‚Äú√öltimo mes‚Äù

‚ÄúAntes del lunes cr√≠tico‚Äù

üëâ Se traducen a rangos temporales expl√≠citos

C. Consultas DE ESTADO (Analyst)

üëâ ‚ÄúC√≥mo est√° un riesgo‚Äù
üëâ ‚ÄúCu√°l es el m√°s importante‚Äù

Ejemplos humanos:

‚ÄúRiesgo dominante‚Äù

‚ÄúPresi√≥n operacional‚Äù

‚ÄúRiesgo emergente‚Äù

D. Consultas COMPARATIVAS (Analyst)

üëâ ‚ÄúComparar modelos‚Äù
üëâ ‚ÄúDesalineaci√≥n‚Äù

Ejemplos humanos:

‚ÄúSubestimado por el modelo proactivo‚Äù

‚ÄúPor qu√© K9 difiere del ranking‚Äù

E. Consultas EVOLUTIVAS (Analyst + Operational)

üëâ ‚ÄúC√≥mo ha evolucionado‚Äù

Ejemplos humanos:

‚ÄúEvoluci√≥n del R02‚Äù

‚ÄúTendencia √∫ltimas semanas‚Äù

F. Consultas NARRATIVAS (Narrative + Analyst)

üëâ ‚ÄúExpl√≠came‚Äù
üëâ ‚ÄúResume‚Äù

Ejemplos humanos:

‚ÄúAn√°lisis del √∫ltimo mes‚Äù

‚ÄúQu√© est√° pasando con los riesgos‚Äù

3Ô∏è‚É£ Lenguaje cognitivo can√≥nico (la clave)

Todo lo anterior se reduce a comandos estructurados, no frases.

Voy a definir el set m√≠nimo y suficiente.

4Ô∏è‚É£ INPUT CAN√ìNICO PARA OPERATIONAL
üìå Forma general
K9/1.0 OPERATIONAL <ACTION> <PARAMS>

4.1 Listar eventos
K9/1.0 OPERATIONAL LIST_EVENTS week_id=2025-W01

K9/1.0 OPERATIONAL LIST_EVENTS date_range=2025-01-01..2025-01-07

4.2 Contar eventos
K9/1.0 OPERATIONAL COUNT_EVENTS week_id=2025-W01

4.3 Contar observaciones
K9/1.0 OPERATIONAL COUNT_OBSERVATIONS week_id=2025-W12


Salida esperada:

{
  "OPG": 34,
  "OCC": 8,
  "TOTAL": 42
}

4.4 Se√±ales temporales clave
K9/1.0 OPERATIONAL GET_SIGNALS before=critical_monday

K9/1.0 OPERATIONAL GET_SIGNALS type=critical_monday

4.5 Eventos por riesgo
K9/1.0 OPERATIONAL LIST_EVENTS risk_id=R01 week_id=2025-W10

üîí Resultado

Si Operational soporta SOLO esto, ya puede responder:

fechas

semanas

enero

lunes cr√≠tico

eventos

observaciones
sin ambig√ºedad

5Ô∏è‚É£ INPUT CAN√ìNICO PARA ANALYST
üìå Forma general
K9/1.0 ANALYST <ACTION> <PARAMS>

5.1 Riesgo dominante
K9/1.0 ANALYST GET_DOMINANT_RISK period=weekly

5.2 Riesgos emergentes
K9/1.0 ANALYST GET_EMERGING_RISKS

5.3 Comparaci√≥n proactivo vs K9
K9/1.0 ANALYST COMPARE_PROACTIVE


Salida esperada:

{
  "underestimated": ["R01"],
  "aligned": ["R02"],
  "overestimated": []
}

5.4 Estado de un riesgo espec√≠fico
K9/1.0 ANALYST EXPLAIN_RISK risk_id=R02 horizon=weekly

5.5 Evoluci√≥n de un riesgo
K9/1.0 ANALYST GET_TREND risk_id=R02 window=4w

5.6 Presi√≥n operacional
K9/1.0 ANALYST GET_OPERATIONAL_PRESSURE

6Ô∏è‚É£ Contrato de salida (CR√çTICO)

Todos los nodos devuelven datos, no texto.

Ejemplo Analyst:

{
  "type": "risk_analysis",
  "risk_id": "R01",
  "status": "emerging",
  "reason": "trend_up + observation_increase",
  "evidence": {
    "weeks": ["2025-W10", "2025-W11"]
  }
}


üëâ El NarrativeNode solo renderiza esto.

7Ô∏è‚É£ Por qu√© con esto se arregla TODO

‚úîÔ∏è ‚Äúqu√© eventos pasaron la primera semana de enero‚Äù
‚Üí OPERATIONAL LIST_EVENTS week_id=2025-W01

‚úîÔ∏è ‚Äúqu√© se√±ales aparecieron antes del lunes cr√≠tico‚Äù
‚Üí OPERATIONAL GET_SIGNALS before=critical_monday

‚úîÔ∏è ‚Äúpor qu√© R01 no aparece en el ranking‚Äù
‚Üí ANALYST COMPARE_PROACTIVE + EXPLAIN_RISK

‚úîÔ∏è ‚Äúdame un an√°lisis del √∫ltimo mes‚Äù
‚Üí ANALYST GET_TREND + OPERATIONAL GET_SIGNALS


---------------------

K9 ‚Äì Canonical Cognitive Command Specification

Versi√≥n 1.0 (Pre-LLM, Determinista)

1. Prop√≥sito del documento

Este documento define el lenguaje cognitivo can√≥nico utilizado internamente por el sistema K9 Mining Safety para interactuar con sus nodos deterministas de an√°lisis:

OperationalAnalysisNode

AnalystNode

El objetivo es desacoplar completamente:

el lenguaje natural,

la l√≥gica de an√°lisis,

la narrativa de salida,

permitiendo que el sistema:

responda cualquier consulta sobre data sint√©tica,

sea verificable por smoke tests,

sea extensible a un LLM sin alterar su n√∫cleo cognitivo.

2. Principios de dise√±o
2.1 Separaci√≥n estricta de responsabilidades
Capa	Rol
Operational	Hechos, conteos, listas, tiempo
Analyst	Interpretaci√≥n, estado, comparaci√≥n
Narrative	Comunicaci√≥n humana
LLM (futuro)	Traducci√≥n NL ‚Üî comandos
2.2 Prohibiciones expl√≠citas

‚ùå Los nodos NO interpretan lenguaje natural

‚ùå Los nodos NO generan narrativa

‚ùå Los nodos NO infieren intenci√≥n

Cada nodo ejecuta comandos cognitivos expl√≠citos.

3. Estructura general del comando
K9/<version> <DOMAIN> <ACTION> <PARAMETERS>

3.1 Componentes
Componente	Descripci√≥n
K9/<version>	Versi√≥n del protocolo cognitivo
DOMAIN	OPERATIONAL | ANALYST
ACTION	Operaci√≥n sem√°ntica
PARAMETERS	Filtros y contexto expl√≠cito

Ejemplo:

K9/1.0 OPERATIONAL LIST_EVENTS week_id=2025-W01

4. Dominio OPERATIONAL
4.1 Rol del dominio OPERATIONAL

El dominio OPERATIONAL expone hechos operacionales verificables, derivados directamente de la data sint√©tica:

eventos

observaciones

auditor√≠as

se√±ales temporales

relaciones riesgo‚Äìevento

No existe interpretaci√≥n ni ranking en este nivel.

4.2 Acciones OPERATIONAL
4.2.1 LIST_EVENTS

Lista eventos operacionales.

K9/1.0 OPERATIONAL LIST_EVENTS
    [week_id=YYYY-WNN]
    [date_range=YYYY-MM-DD..YYYY-MM-DD]
    [risk_id=RXX]
    [event_type=incident|near_miss]


Salida est√°ndar:

{
  "events": [
    {
      "event_id": "EVT-1023",
      "date": "2025-01-03",
      "risk_id": "R01",
      "type": "near_miss"
    }
  ]
}

4.2.2 COUNT_EVENTS

Cuenta eventos bajo un filtro.

K9/1.0 OPERATIONAL COUNT_EVENTS week_id=2025-W01

{
  "count": 7
}

4.2.3 LIST_OBSERVATIONS
K9/1.0 OPERATIONAL LIST_OBSERVATIONS
    [week_id=YYYY-WNN]
    [risk_id=RXX]
    [observation_type=OPG|OCC]

4.2.4 COUNT_OBSERVATIONS
K9/1.0 OPERATIONAL COUNT_OBSERVATIONS week_id=2025-W12

{
  "OPG": 34,
  "OCC": 8,
  "TOTAL": 42
}

4.2.5 GET_SIGNALS

Obtiene se√±ales temporales relevantes.

K9/1.0 OPERATIONAL GET_SIGNALS before=critical_monday

{
  "signals": [
    {
      "risk_id": "R02",
      "occ_count": 5,
      "opg_count": 12
    }
  ]
}

4.2.6 GET_TIMELINE

Devuelve una l√≠nea de tiempo operacional.

K9/1.0 OPERATIONAL GET_TIMELINE risk_id=R02 window=4w

5. Dominio ANALYST
5.1 Rol del dominio ANALYST

El dominio ANALYST interpreta el estado del sistema utilizando:

resultados OPERATIONAL

m√©tricas

comparaciones de modelos

reglas deterministas

Nunca accede a datos crudos sin pasar por OPERATIONAL.

5.2 Acciones ANALYST
5.2.1 GET_DOMINANT_RISK
K9/1.0 ANALYST GET_DOMINANT_RISK period=weekly

{
  "risk_id": "R02",
  "reason": "highest_operational_pressure"
}

5.2.2 GET_EMERGING_RISKS
K9/1.0 ANALYST GET_EMERGING_RISKS

{
  "risks": ["R01"]
}

5.2.3 EXPLAIN_RISK
K9/1.0 ANALYST EXPLAIN_RISK risk_id=R02 horizon=weekly

{
  "risk_id": "R02",
  "status": "emerging",
  "drivers": ["occ_trend_up", "event_density"]
}

5.2.4 GET_TREND
K9/1.0 ANALYST GET_TREND risk_id=R02 window=4w

5.2.5 COMPARE_PROACTIVE
K9/1.0 ANALYST COMPARE_PROACTIVE

{
  "underestimated": ["R01"],
  "aligned": ["R02"],
  "overestimated": []
}

5.2.6 GET_OPERATIONAL_PRESSURE
K9/1.0 ANALYST GET_OPERATIONAL_PRESSURE

6. Contrato de salida (obligatorio)

Todos los nodos devuelven:

{
  "type": "<analysis_type>",
  "payload": { ... },
  "traceability": {
    "inputs": [...],
    "rules_applied": [...]
  }
}


Esto permite:

auditor√≠a,

replay,

explicaci√≥n,

testing determinista.

7. Relaci√≥n con Narrative y LLM

NarrativeNode:
Consume payload y lo traduce a lenguaje humano.

LLM (futuro):
Traduce lenguaje natural ‚Üî comandos K9/1.0.

El n√∫cleo no cambia.

8. Beneficios clave

‚úîÔ∏è Responde cualquier consulta sobre data sint√©tica
‚úîÔ∏è Smoke tests deterministas
‚úîÔ∏è Cero dependencia de NL
‚úîÔ∏è Preparado para agentes y multi-LLM
‚úîÔ∏è Auditable y explicable

9. Estado

Este documento define el lenguaje cognitivo oficial de K9
y debe considerarse contrato estable para los nodos internos.

------------------

K9 ‚Äì Canonical Cognitive Command Specification
Versi√≥n 1.1 ‚Äì Full Temporal & Data Coverage
1. Principio rector (nuevo, expl√≠cito)

Toda la data sint√©tica del sistema K9 debe ser consultable expl√≠citamente por tiempo.

Esto incluye sin excepci√≥n:

eventos

observaciones (OPG / OCC)

auditor√≠as (preventivas / reactivas)

FDO

scores del modelo proactivo

m√©tricas derivadas

Si algo no puede consultarse por fecha, no existe cognitivamente.

2. Normalizaci√≥n temporal (obligatoria)

Todos los comandos aceptan uno y solo uno de los siguientes par√°metros temporales:

Par√°metro	Ejemplo	Uso
date	2025-01-07	d√≠a espec√≠fico
week_id	2025-W01	semana ISO
date_range	2025-01-01..2025-01-07	rango expl√≠cito
relative	last_week, last_4w	abstracci√≥n temporal

‚ö†Ô∏è Regla dura
Si no hay par√°metro temporal ‚Üí error cognitivo (excepto estados globales).

3. Dominio OPERATIONAL (extensi√≥n completa)
3.1 LIST_EVENTS
K9/1.1 OPERATIONAL LIST_EVENTS
    time=week_id:2025-W01
    [risk_id=R01]
    [event_type=incident|near_miss]


Salida

{
  "events": [
    {
      "event_id": "EVT-021",
      "date": "2025-01-03",
      "week_id": "2025-W01",
      "risk_id": "R01",
      "type": "near_miss",
      "severity": "low"
    }
  ]
}

3.2 LIST_OBSERVATIONS
K9/1.1 OPERATIONAL LIST_OBSERVATIONS
    time=date_range:2025-01-01..2025-01-07
    [risk_id=R02]
    [type=OPG|OCC]

{
  "observations": [
    {
      "obs_id": "OBS-334",
      "date": "2025-01-05",
      "type": "OCC",
      "risk_id": "R02",
      "control_id": "CC-07"
    }
  ]
}

3.3 LIST_AUDITS (nuevo ‚Äì obligatorio)
K9/1.1 OPERATIONAL LIST_AUDITS
    time=week_id:2025-W01
    [audit_type=preventive|reactive]

{
  "audits": [
    {
      "audit_id": "AUD-009",
      "date": "2025-01-04",
      "type": "reactive",
      "trigger_event": "EVT-021"
    }
  ]
}

3.4 LIST_FDO (nuevo)
K9/1.1 OPERATIONAL LIST_FDO
    time=date_range:2025-01-01..2025-01-07
    [factor=production_pressure|fatigue|backlog]

{
  "fdo": [
    {
      "date": "2025-01-02",
      "factor": "production_pressure",
      "value": 0.72
    }
  ]
}

3.5 GET_PROACTIVE_SCORES (nuevo)
K9/1.1 OPERATIONAL GET_PROACTIVE_SCORES
    time=week_id:2025-W01
    [risk_id=R01]

{
  "scores": [
    {
      "risk_id": "R01",
      "score": 0.31,
      "rank": 4
    }
  ]
}

3.6 COUNT_* (todos los dominios)

Todos los objetos anteriores tienen su versi√≥n COUNT_*:

COUNT_EVENTS

COUNT_OBSERVATIONS

COUNT_AUDITS

COUNT_FDO_ENTRIES

Siempre con time=....

4. Dominio ANALYST (alineado a OPERATIONAL)
4.1 Regla fundamental

El Analyst nunca inventa datos.
Solo razona sobre salidas OPERATIONAL.

4.2 GET_DOMINANT_RISK
K9/1.1 ANALYST GET_DOMINANT_RISK
    time=week_id:2025-W01

{
  "risk_id": "R02",
  "drivers": [
    "high_occ_density",
    "event_accumulation",
    "fdo_pressure"
  ]
}

4.3 EXPLAIN_RISK
K9/1.1 ANALYST EXPLAIN_RISK
    risk_id=R02
    time=last_4w

{
  "risk_id": "R02",
  "status": "emerging",
  "trend": "upward",
  "evidence": [
    "occ_increase",
    "fdo_pressure",
    "proactive_gap"
  ]
}

4.4 COMPARE_PROACTIVE
K9/1.1 ANALYST COMPARE_PROACTIVE
    time=week_id:2025-W01

{
  "underestimated": ["R01"],
  "aligned": ["R02"],
  "overestimated": []
}

4.5 GET_OPERATIONAL_PRESSURE
K9/1.1 ANALYST GET_OPERATIONAL_PRESSURE
    time=last_2w

5. NarrativeNode (impacto directo)

El NarrativeNode deja de ‚Äúadivinar‚Äù y solo:

detecta el tipo de payload

ordena

redacta

Ejemplo:

LIST_EVENTS ‚Üí narrativa descriptiva

COUNT_OBSERVATIONS ‚Üí narrativa factual

EXPLAIN_RISK ‚Üí narrativa anal√≠tica

Nunca m√°s:

‚Äúriesgo dominante‚Äù sin tiempo

‚Äúse√±ales antes del lunes‚Äù sin rango expl√≠cito

--------------

Extensi√≥n K9/1.1 ‚Äî TRAYECTORIAS (obligatorio)
1. Qu√© es una trayectoria en K9 (definici√≥n operativa)

Una trayectoria es una serie temporal ‚Äúcan√≥nica‚Äù asociada a un risk_id (y opcionalmente a area_id) que representa la evoluci√≥n del riesgo en el tiempo, incluyendo:

score K9 (se√±ales semanales / diarias seg√∫n dataset)

presi√≥n operacional / degradaci√≥n (si existe derivado)

marca de umbrales (amarillo/rojo o critical_threshold)

hitos (p.ej. lunes cr√≠tico)

La trayectoria es el ‚Äúeje X‚Äù al que se anclan observaciones, eventos, FDO y auditor√≠as.

2. Normalizaci√≥n temporal espec√≠fica de trayectorias

Trayectorias deben soportar:

granularity=weekly|daily

time=week_id|date|date_range|relative

Regla:

Si granularity=weekly ‚Üí time se interpreta como semanas.

Si granularity=daily ‚Üí time se interpreta como fechas.

3. Comandos OPERATIONAL de trayectorias
3.1 GET_TRAJECTORY (core)
K9/1.1 OPERATIONAL GET_TRAJECTORY
    risk_id=R02
    granularity=weekly
    time=last_12w
    [series=k9_score|threshold|pressure]


Salida

{
  "trajectory": {
    "risk_id": "R02",
    "granularity": "weekly",
    "points": [
      {"week_id": "2025-W01", "k9_score": 0.83, "threshold": 0.80},
      {"week_id": "2025-W02", "k9_score": 0.82, "threshold": 0.80}
    ]
  }
}

3.2 LIST_TRAJECTORIES (multi-risk)
K9/1.1 OPERATIONAL LIST_TRAJECTORIES
    granularity=weekly
    time=week_id:2025-W01
    [risk_ids=R01,R02,R03]


Salida

{
  "trajectories": [
    {"risk_id": "R01", "week_id": "2025-W01", "k9_score": 0.61},
    {"risk_id": "R02", "week_id": "2025-W01", "k9_score": 0.83},
    {"risk_id": "R03", "week_id": "2025-W01", "k9_score": 0.44}
  ]
}

3.3 DETECT_THRESHOLD_BREACHES (nuevo)
K9/1.1 OPERATIONAL DETECT_THRESHOLD_BREACHES
    granularity=weekly
    time=last_12w
    threshold=0.80


Salida

{
  "breaches": [
    {"risk_id": "R02", "first_breach": "2025-W01", "sustained": true},
    {"risk_id": "R01", "first_breach": null, "sustained": false}
  ]
}

3.4 GET_CRITICAL_MONDAY_CONTEXT (nuevo)

Este comando existe porque el ‚Äúlunes cr√≠tico‚Äù no es un texto: es un ancla temporal del sistema.

K9/1.1 OPERATIONAL GET_CRITICAL_MONDAY_CONTEXT
    time=week_id:2025-W12


Salida

{
  "critical_monday": {
    "date": "2025-03-17",
    "week_id": "2025-W12",
    "leading_window": "2025-03-10..2025-03-16"
  }
}

4. Comandos ANALYST sobre trayectorias
4.1 EXPLAIN_TRAJECTORY
K9/1.1 ANALYST EXPLAIN_TRAJECTORY
    risk_id=R01
    granularity=weekly
    time=last_12w


Salida

{
  "risk_id": "R01",
  "trend": "upward",
  "pattern": "emerging",
  "notes": [
    "weak_signals_accumulating",
    "approaching_threshold"
  ]
}

4.2 COMPARE_TRAJECTORIES
K9/1.1 ANALYST COMPARE_TRAJECTORIES
    granularity=weekly
    time=last_8w
    risk_ids=R01,R02

4.3 LINK_SIGNALS_TO_OPERATIONS (nuevo, clave para narrativa)

Este es el puente determinista que te faltaba para preguntas tipo:
‚Äúdame los eventos de la semana 1‚Äù + ‚Äúy c√≥mo eso afecta la trayectoria‚Äù.

K9/1.1 ANALYST LINK_SIGNALS_TO_OPERATIONS
    risk_id=R01
    time=week_id:2025-W01
    granularity=weekly


Salida

{
  "risk_id": "R01",
  "week_id": "2025-W01",
  "trajectory_point": {"k9_score": 0.61, "threshold": 0.80},
  "drivers": {
    "events": 2,
    "occ": 3,
    "opg": 7,
    "fdo_factors": ["production_pressure"]
  }
}

5. Impacto directo en el Smoke (correcci√≥n)

Ahora el smoke can√≥nico debe incluir trayectorias s√≠ o s√≠.

Ejemplos:

K9/1.1 OPERATIONAL GET_TRAJECTORY risk_id=R02 granularity=weekly time=last_12w

K9/1.1 OPERATIONAL DETECT_THRESHOLD_BREACHES granularity=weekly time=last_12w threshold=0.80

K9/1.1 ANALYST LINK_SIGNALS_TO_OPERATIONS risk_id=R01 time=week_id:2025-W01 granularity=weekly


Si esto pasa, entonces despu√©s puedes traducir desde NL con LLM.

6. Checklist de cobertura (ahora s√≠ completo)

Eventos ‚úÖ

Observaciones ‚úÖ

Auditor√≠as ‚úÖ

FDO ‚úÖ

Proactivo ‚úÖ

Trayectorias ‚úÖ (faltaba, ya est√°)

Umbrales + breach ‚úÖ

Contexto lunes cr√≠tico ‚úÖ


---------------

K9 ‚Äî Propuesta Agn√≥stica de Arquitectura Cognitiva (v1.0)

Objetivo:
Permitir que el sistema K9 pueda responder cualquier consulta sobre data sint√©tica (pasada, presente o agregada), sin depender de lenguaje natural, y sin asumir estructura concreta de datasets.

El LLM no razona datos, solo traduce entre:

Lenguaje humano ‚Üî comandos can√≥nicos

Resultados estructurados ‚Üî narrativa final

1. Principio rector (clave)

Ning√∫n nodo interpreta lenguaje natural.
Todos los nodos operan sobre comandos can√≥nicos.

El problema que viste en el smoke no es un bug, es una se√±al correcta:

Est√°bamos forzando NL sin traductor (LLM)

El sistema respondi√≥ ‚Äúlo que pod√≠a‚Äù, no ‚Äúlo que deb√≠a‚Äù

2. Capas del sistema (clarificaci√≥n definitiva)
2.1 Data Engine (HECHOS PUROS)

Responsabilidad √∫nica:

Exponer TODA la data disponible, normalizada, sin interpretaci√≥n.

Nunca responde ‚Äúpor qu√©‚Äù ni ‚Äúqu√© significa‚Äù.

Expone cat√°logos temporales:

engine.events
engine.observations
engine.audits
engine.fdo
engine.proactive
engine.trajectories


Cada uno debe cumplir:

{
  "entity": "...",
  "time_axis": "daily|weekly",
  "available_ranges": ["2025-W01..2025-W12"],
  "indexed_by": ["risk_id", "area_id", "date"]
}

2.2 Operational Analysis Node (CONSULTAS FACTUALES)

Responsabilidad:

Responder qu√© pas√≥, cu√°ndo, cu√°nto, d√≥nde, para qui√©n.

Nunca interpreta tendencias.

Ejemplos que DEBE poder responder

‚ÄúEventos semana 1‚Äù

‚ÄúObservaciones R02 √∫ltima semana‚Äù

‚ÄúAuditor√≠as por √°rea en marzo‚Äù

‚ÄúTrayectoria semanal R01‚Äù

‚ÄúFDO por fecha‚Äù

Lenguaje can√≥nico
K9 OPERATIONAL QUERY
    entity=events
    time=week_id:2025-W01
    [risk_id=R01]


Salida:

{
  "events": [...],
  "count": 3
}

2.3 Analyst Node (RAZONAMIENTO DETERMINISTA)

Responsabilidad:

Conectar hechos ‚Üí patrones ‚Üí conclusiones estructuradas.

Nunca inventa datos.
Nunca hace narrativa libre.

Opera SOLO sobre outputs del Operational.

Capacidades m√≠nimas

Detectar tendencia (up/down/stable)

Detectar acumulaci√≥n de se√±ales

Detectar desalineaci√≥n proactivo vs K9

Asociar se√±ales a trayectoria

Marcar hitos temporales (lunes cr√≠tico)

Lenguaje can√≥nico
K9 ANALYST EXPLAIN
    subject=trajectory
    risk_id=R02
    time=last_12w


Salida:

{
  "risk_id": "R02",
  "trend": "upward",
  "pattern": "emerging",
  "drivers": ["events", "occ", "fdo"]
}

3. Trayectorias (primer-clase, agn√≥stico)
3.1 Contrato m√≠nimo
trajectory = {
  "risk_id": "R02",
  "granularity": "weekly",
  "points": [
    {
      "time": "2025-W01",
      "score": 0.82,
      "threshold": 0.80
    }
  ]
}

3.2 Regla de oro

Todo an√°lisis temporal debe anclarse a una trayectoria.

Si no hay trayectoria ‚Üí el Analyst no opina.

4. Narrative Node (TRADUCTOR, no analista)

Responsabilidad correcta:

Convertir estado estructurado en lenguaje humano coherente,
sin agregar informaci√≥n nueva.

Inputs v√°lidos

operational_results

analyst_results

state.context (intento, tiempo, riesgos)

Prohibiciones

‚ùå No inferir datos

‚ùå No decidir qu√© consultar

‚ùå No reemplazar Analyst

Ejemplo

Input:

{
  "analyst": {
    "risk_id": "R02",
    "trend": "upward",
    "pattern": "emerging"
  }
}


Output:

‚ÄúEl riesgo R02 muestra una tendencia creciente en las √∫ltimas semanas, asociada a una acumulaci√≥n progresiva de se√±ales operacionales.‚Äù

5. Smoke Tests ‚Äî correcci√≥n conceptual (CR√çTICO)

El smoke NO debe usar lenguaje natural en esta fase.

‚ùå Incorrecto (actual)
"¬øQu√© se√±ales aparecieron antes del lunes cr√≠tico?"

‚úÖ Correcto (ahora)
K9 OPERATIONAL QUERY
    entity=signals
    time=before:critical_monday


o

K9 ANALYST EXPLAIN
    subject=signals
    time=before:critical_monday


El NL vendr√° despu√©s, v√≠a LLM.

6. Flujo final correcto (visi√≥n completa)
Usuario (NL)
   ‚Üì
LLM Translator
   ‚Üì
Comando Can√≥nico
   ‚Üì
Operational / Analyst
   ‚Üì
Resultados estructurados
   ‚Üì
Narrative Node
   ‚Üì
Respuesta humana

7. Por qu√© ahora todo encaja

‚ùå No era un problema del narrative node

‚ùå No era un bug del analyst

‚ùå No era falta de datos

‚úîÔ∏è Era orden cognitivo incorrecto
‚úîÔ∏è El sistema estaba ‚Äúpensando en humano‚Äù sin traductor

--------------------

K9 Mining Safety
Documento Formal de Comandos Can√≥nicos y Arquitectura Cognitiva

Versi√≥n: 1.0
Estado: Especificaci√≥n base aprobable
√Åmbito: Sistema Cognitivo K9 ‚Äì Data Sint√©tica y Real
Idioma del sistema: Espa√±ol (lenguaje cognitivo interno independiente del idioma humano)

1. Prop√≥sito del Documento

Este documento define de manera formal:

La arquitectura cognitiva funcional del sistema K9.

El lenguaje can√≥nico mediante el cual los nodos interact√∫an.

Las responsabilidades exactas de cada nodo.

El contrato que garantiza que cualquier consulta sobre data sint√©tica pueda ser respondida correctamente.

La separaci√≥n estricta entre:

Hechos

Razonamiento

Narrativa

Traducci√≥n ling√º√≠stica (LLM)

Este documento precede a cualquier integraci√≥n de LLM y no depende de datasets espec√≠ficos.

2. Principio Fundacional (No negociable)

El sistema K9 no razona lenguaje natural.
Razonar lenguaje natural es responsabilidad exclusiva del LLM.

El n√∫cleo cognitivo K9 opera √∫nicamente sobre comandos can√≥nicos estructurados.

3. Capas del Sistema Cognitivo K9
3.1 Capa de Datos ‚Äî Data Engine Node
Rol

Exponer toda la data disponible de forma:

Completa

Indexada

Temporalmente consistente

Sin interpretaci√≥n

Regla clave

El Data Engine no responde preguntas, solo entrega hechos.

Universos de datos soportados (agn√≥stico)
Universo	Descripci√≥n
events	Eventos operacionales
observations	Observaciones (OCC / OPG)
audits	Auditor√≠as
fdo	Factores Din√°micos Operacionales
proactive	Resultados del modelo proactivo
trajectories	Trayectorias temporales de riesgo
Contrato m√≠nimo de salida
{
  "entity": "events",
  "records": [...],
  "time_axis": "daily|weekly",
  "available_ranges": ["2025-W01..2025-W12"],
  "indexed_by": ["risk_id", "area_id", "date"]
}

4. Lenguaje Can√≥nico K9 (Base del Sistema)
4.1 Definici√≥n

El Lenguaje Can√≥nico K9 es un conjunto de comandos estructurados que representan intenciones cognitivas expl√≠citas, no lenguaje humano.

5. Operational Analysis Node
5.1 Responsabilidad

Responder consultas factuales sobre la data:

Qu√© ocurri√≥

Cu√°ndo ocurri√≥

Cu√°ntos registros existen

Para qu√© riesgo / √°rea / per√≠odo

No interpreta, no compara, no concluye.

5.2 Tipos de consultas soportadas
Tipo	Ejemplo
Conteo	Observaciones semana 3
Listado	Eventos semana 1
Filtro	Auditor√≠as por √°rea
Temporal	FDO entre fechas
Trayectoria	Serie semanal de riesgo
5.3 Comando can√≥nico: OPERATIONAL QUERY
K9 OPERATIONAL QUERY
    entity=observations
    time=week:2025-W03
    risk_id=R02

Salida est√°ndar
{
  "entity": "observations",
  "risk_id": "R02",
  "time": "2025-W03",
  "occ_count": 4,
  "opg_count": 2
}

6. Trayectorias (Entidad de Primera Clase)
6.1 Definici√≥n formal

Una trayectoria representa la evoluci√≥n temporal cuantificada de un riesgo.

{
  "risk_id": "R02",
  "granularity": "weekly",
  "points": [
    {
      "time": "2025-W01",
      "score": 0.72,
      "threshold": 0.80
    }
  ]
}

6.2 Regla de oro

Ning√∫n an√°lisis temporal es v√°lido sin trayectoria.

7. Analyst Node (Razonamiento Determinista)
7.1 Responsabilidad

Transformar hechos en interpretaciones estructuradas, sin lenguaje natural libre.

Opera exclusivamente sobre:

Outputs del Data Engine

Outputs del Operational Node

Trayectorias

7.2 Capacidades obligatorias

Detecci√≥n de tendencia

Identificaci√≥n de patrones emergentes

Comparaci√≥n proactivo vs K9

Identificaci√≥n de hitos temporales

Asociaci√≥n causa‚Äìse√±al‚Äìriesgo

7.3 Comando can√≥nico: ANALYST EXPLAIN
K9 ANALYST EXPLAIN
    subject=trajectory
    risk_id=R02
    time=last_12w

Salida est√°ndar
{
  "risk_id": "R02",
  "trend": "upward",
  "pattern": "emerging",
  "drivers": ["events", "occ", "fdo"],
  "confidence": "high"
}

8. Comparaci√≥n Proactivo vs K9 (Formal)
8.1 Contrato
{
  "risk_id": "R02",
  "proactive_rank": 4,
  "k9_rank": 1,
  "alignment_status": "underestimated_by_proactive"
}

8.2 Estados v√°lidos

aligned

underestimated_by_proactive

overestimated_by_proactive

insufficient_data

9. Narrative Node (Traducci√≥n Sem√°ntica)
9.1 Rol real (no negociable)

El Narrative Node no razona.
El Narrative Node no consulta datos.

Su √∫nica funci√≥n es:

Traducir resultados estructurados ‚Üí lenguaje humano coherente.

9.2 Inputs v√°lidos

operational_results

analyst_results

proactive_comparison

state.context

9.3 Output esperado

Texto narrativo fiel al contenido estructurado, sin agregar informaci√≥n.

10. LLM (Fase Posterior)
10.1 Rol del LLM

Traducir lenguaje humano ‚Üí comandos can√≥nicos

Traducir narrativa estructurada ‚Üí lenguaje natural final

10.2 Prohibiciones

‚ùå El LLM no accede a data

‚ùå El LLM no razona riesgos

‚ùå El LLM no calcula m√©tricas

11. Smoke Tests Correctos (Can√≥nicos)
11.1 Ejemplos v√°lidos
K9 OPERATIONAL QUERY
    entity=events
    time=week:2025-W01

K9 ANALYST EXPLAIN
    subject=signals
    time=before:critical_monday

12. Conclusi√≥n Formal

Con esta arquitectura:

El sistema puede responder cualquier consulta sobre data sint√©tica

El lenguaje natural deja de ser una dependencia temprana

Los nodos quedan blindados, testeables y auditables

El LLM se integra sin riesgo de alucinaci√≥n estructural

Pr√≥ximo paso recomendado

Crear K9 Canonical Command Spec v1.0 (archivo √∫nico)

Reescribir smoke tests solo en lenguaje can√≥nico

Validar cobertura completa de:

eventos

observaciones

auditor√≠as

FDO

trayectorias

modelo proactivo

Reci√©n despu√©s ‚Üí integrar LLM

Si quieres, en el siguiente mensaje puedo:

Redactar el Command Spec formal

Dise√±ar la suite completa de smoke can√≥nicos

Proponer la estructura del prompt del LLM traductor

-------------

1. Para qu√© serv√≠a el intent hasta ahora (y por qu√© funcion√≥)

El intent actual naci√≥ para simular algo que a√∫n no exist√≠a:

Un LLM traductor

Un lenguaje can√≥nico estable

Comandos cognitivos formales

Por eso hoy hace cosas como:

Inferir ‚Äúanalyst‚Äù, ‚Äúriesgos‚Äù, ‚Äúproactive_model‚Äù, etc.

Actuar como un pseudo-parser de lenguaje natural

Decidir rutas del grafo con heur√≠sticas fr√°giles (keywords)

üëâ Eso era correcto en Fase 1, porque:

Permit√≠a avanzar sin LLM

Permit√≠a probar nodos

Permit√≠a construir el pipeline cognitivo

Hasta aqu√≠: bien dise√±ado para su momento.

2. Qu√© cambi√≥ ahora (y por qu√© el intent empieza a fallar)

Con lo que acabamos de formalizar, el sistema ya no es un chatbot experimental, sino un sistema cognitivo determinista.

Y eso cambia una regla fundamental:

El sistema no debe inferir intenci√≥n desde lenguaje natural
La intenci√≥n debe venir expl√≠cita en el comando can√≥nico

Hoy est√°s forzando al intent a hacer algo imposible:

Deducir si una pregunta es:

factual

anal√≠tica

temporal

comparativa

Sin LLM

Sin sem√°ntica completa

Con datos que ya existen pero no se enrutan bien

Por eso ves s√≠ntomas como:

Respuestas correctas en contenido, incorrectas en foco

Preguntas de ‚Äúlunes cr√≠tico‚Äù que no activan evidencia

Conteos de observaciones que caen en fallback

Smoke tests fr√°giles que buscan tokens en texto

üëâ No es un bug puntual
üëâ Es una se√±al arquitect√≥nica

3. Entonces‚Ä¶ ¬øel intent se elimina?

No. Pero cambia radicalmente de naturaleza.

Antes (lo que tienes hoy)

intent = inferencia ling√º√≠stica

Ahora (lo que corresponde)

intent = comando cognitivo expl√≠cito

4. El nuevo rol correcto del intent

El intent pasa a ser una etiqueta estructural, no una inferencia.

Ejemplo correcto (sin LLM)
state.intent = "OPERATIONAL_QUERY"
state.command = {
    "entity": "observations",
    "time": "week:2025-W03",
    "risk_id": "R02"
}


Aqu√≠ el intent:

No interpreta

No adivina

No razona

Solo declara el tipo de operaci√≥n cognitiva.

5. Qu√© pasa con el intent_classifier actual

Debe degradarse, no eliminarse.

Nuevo rol transitorio (muy importante)

Mientras no haya LLM:

El intent_classifier:

Traduce lenguaje de sistema (no humano)

Acepta comandos semi-estructurados

Falla de forma expl√≠cita si la intenci√≥n no es clara

Ejemplo aceptable ahora:

QUERY: OPERATIONAL observations week=2025-W01 risk=R02


Ejemplo no aceptable (sin LLM):

¬øQu√© pas√≥ antes del lunes cr√≠tico?


üëâ Y esto es clave:
El smoke test estaba mal dise√±ado, no el sistema.

6. Qu√© va a pasar cuando entre el LLM

Ah√≠ el intent vuelve a cambiar de rol, por tercera vez:

Con LLM

El LLM:

Traduce lenguaje humano ‚Üí comando can√≥nico

El intent:

Solo valida el comando

Nunca infiere sem√°ntica

7. Resumen claro (para decisi√≥n)
Etapa	Intent
Fase 1 (pasada)	Inferencia heur√≠stica
Fase 2 (ahora)	Selector de comando can√≥nico
Fase 3 (con LLM)	Validador de intenci√≥n expl√≠cita
8. Recomendaci√≥n concreta (siguiente paso)

Congelar el intent actual (no seguir parche√°ndolo)

Definir formalmente:

OPERATIONAL_QUERY

ANALYST_EXPLAIN

PROACTIVE_COMPARE

Reescribir los smoke tests en lenguaje can√≥nico

Dejar expl√≠cito:

El sistema no entiende lenguaje natural sin LLM

Con eso:

Desaparecen los errores de ‚Äúlunes‚Äù, ‚Äúobservaciones‚Äù, ‚ÄúR02‚Äù

El Narrative deja de ser forzado

El sistema se vuelve coherente consigo mismo

Si quieres, en el pr√≥ximo mensaje puedo:

Proponer la nueva versi√≥n exacta del intent_classifier

Dise√±ar un set de comandos can√≥nicos reales

Reescribir un smoke test correcto y robusto

-------------


üìò K9 Canonical Cognitive Language v1

Sistema de Comandos Cognitivos Deterministas

1. Prop√≥sito del Lenguaje Can√≥nico

El Lenguaje Can√≥nico define c√≥mo el sistema K9 piensa internamente.

No es lenguaje natural.
No es intenci√≥n inferida.
No es narrativa.

Es un contrato estructural expl√≠cito entre:

Entrada (comando cognitivo)

Motor cognitivo (nodos)

Estado (K9State)

Salida estructurada

üëâ El LLM no razona, solo traduce:

lenguaje humano ‚Üí lenguaje can√≥nico
lenguaje can√≥nico ‚Üí narrativa humana

2. Principios de Dise√±o

Agn√≥stico a idioma

Determinista

Validable

Extensible

Temporalmente expl√≠cito

Cobertura total de la data sint√©tica

3. Estructura Base del Comando Can√≥nico

Todo comando K9 DEBE cumplir esta estructura m√≠nima:

{
  "intent": "<CANONICAL_INTENT>",
  "entity": "<PRIMARY_ENTITY>",
  "operation": "<OPERATION>",
  "filters": {},
  "time": {},
  "group_by": [],
  "output": "<OUTPUT_MODE>"
}

4. Intents Can√≥nicos Oficiales (v1)
4.1 OPERATIONAL_QUERY

Consultas factuales sobre la data.

üëâ No interpretaci√≥n
üëâ No juicio
üëâ No inferencia

Ejemplos:

observaciones

eventos

auditor√≠as

FDO

trayectorias

modelo proactivo (valores)

4.2 ANALYTICAL_QUERY

Consultas de interpretaci√≥n, evoluci√≥n o relaci√≥n.

üëâ Comparaciones
üëâ Tendencias
üëâ Degradaci√≥n
üëâ Emergencia

4.3 COMPARATIVE_QUERY

Comparaci√≥n expl√≠cita entre modelos o fuentes.

Ejemplo:

K9 vs Modelo Proactivo

4.4 SYSTEM_QUERY

Estado del sistema, cobertura, disponibilidad.

5. Entidades Can√≥nicas (entity)
Entity	Descripci√≥n
observations	OCC / OPG
events	Eventos operacionales
audits	Auditor√≠as
fdo	Factores Din√°micos Operacionales
trajectories	Trayectorias de riesgo
risks	Riesgos (R01, R02, ‚Ä¶)
proactive_model	Ranking / scores proactivos
signals	Se√±ales compuestas
areas	√Åreas operacionales
6. Operaciones (operation)
Operaciones Factuales

list

count

summarize

retrieve

Operaciones Anal√≠ticas

evolution

trend

compare

detect

explain

7. Dimensi√≥n Temporal (time)

La temporalidad nunca es impl√≠cita.

"time": {
  "type": "relative | absolute | window",
  "value": "last_week | 2025-01-01 | pre_critical_monday"
}


Ejemplos v√°lidos:

"last_week"

"week:2025-W01"

"pre_critical_monday"

"between:2025-01-01,2025-01-07"

8. Filtros (filters)
"filters": {
  "risk_id": ["R01", "R02"],
  "area": ["Planta Concentradora"],
  "type": ["OCC", "OPG"]
}

9. Agrupaci√≥n (group_by)
"group_by": ["risk", "type", "area", "week"]

10. Modo de Salida (output)
Output	Uso
raw	Data estructurada
summary	Resumen factual
analysis	Interpretaci√≥n
narrative	Texto humano

‚ö†Ô∏è NarrativeNode solo se activa si output = narrative

11. Ejemplos Can√≥nicos Reales
11.1 ‚Äú¬øQu√© se√±ales aparecieron antes del lunes cr√≠tico?‚Äù
{
  "intent": "OPERATIONAL_QUERY",
  "entity": "signals",
  "operation": "list",
  "time": {
    "type": "relative",
    "value": "pre_critical_monday"
  },
  "output": "summary"
}

11.2 ‚Äú¬øCu√°ntas observaciones hubo la semana pasada y de qu√© tipo?‚Äù
{
  "intent": "OPERATIONAL_QUERY",
  "entity": "observations",
  "operation": "count",
  "time": {
    "type": "relative",
    "value": "last_week"
  },
  "group_by": ["type"],
  "output": "summary"
}

11.3 ‚Äú¬øPor qu√© el modelo proactivo no refleja R01?‚Äù
{
  "intent": "COMPARATIVE_QUERY",
  "entity": "proactive_model",
  "operation": "compare",
  "filters": {
    "risk_id": ["R01"]
  },
  "output": "analysis"
}

11.4 ‚ÄúEvoluci√≥n del riesgo R02 en el √∫ltimo mes‚Äù
{
  "intent": "ANALYTICAL_QUERY",
  "entity": "trajectories",
  "operation": "evolution",
  "filters": {
    "risk_id": ["R02"]
  },
  "time": {
    "type": "relative",
    "value": "last_month"
  },
  "output": "analysis"
}

12. Impacto Directo en tu Sistema Actual
‚úÖ Lo que se mantiene

DataEngineNode

OperationalAnalysisNode

AnalystNode

MetricsNode

NarrativeNode

State

üîÅ Lo que cambia

intent_classifier deja de inferir ‚Üí valida

smoke deja de usar lenguaje natural

NarrativeNode deja de compensar errores

El sistema deja de ‚Äúadivinar‚Äù

13. Frase Clave (importante)

El lenguaje can√≥nico no reemplaza al LLM.
Lo precede.
Y lo gobierna.

-----------

Revisi√≥n Cr√≠tica del Lenguaje Can√≥nico v1
(Gap Analysis + Extensiones Necesarias)
1. Evaluaci√≥n del v1 actual

Lo que ya est√° bien cubierto:

Consultas:

Observaciones (OCC / OPG)

Eventos

Auditor√≠as

FDO

Trayectorias

Modelo proactivo

Dimensi√≥n temporal expl√≠cita

Separaci√≥n:

OPERATIONAL_QUERY

ANALYTICAL_QUERY

COMPARATIVE_QUERY

Operaciones:

list, count, summarize

evolution, compare, explain

üëâ Esto cubre aprox. 70‚Äì75% del espacio real de consultas.

2. Comandos que FALTAN (y por qu√© son cr√≠ticos)
2.1 ‚ùå Falta: consultas por evento concreto / identificador

Hoy NO existe una forma can√≥nica de decir:

‚ÄúDame el detalle del evento X‚Äù
‚ÄúMu√©strame la observaci√≥n OCC_0123‚Äù

üî¥ Problema

Sin esto:

No hay drill-down

No hay trazabilidad

No hay explicaci√≥n causal fina

‚úÖ Comando que falta
Nuevo operation: retrieve_by_id
{
  "intent": "OPERATIONAL_QUERY",
  "entity": "events",
  "operation": "retrieve_by_id",
  "filters": {
    "event_id": ["EVT_2025_0012"]
  },
  "output": "raw"
}


‚úîÔ∏è Este comando es obligatorio para:

demos cre√≠bles

explicabilidad

navegaci√≥n real de la data

2.2 ‚ùå Falta: consultas por secuencia temporal

Hoy puedes pedir:

‚Äú√∫ltima semana‚Äù

‚Äú√∫ltimo mes‚Äù

Pero NO puedes pedir:

‚Äúqu√© pas√≥ ANTES y DESPU√âS del evento X‚Äù
‚Äúqu√© ocurri√≥ entre la auditor√≠a A y el lunes cr√≠tico‚Äù

üî¥ Problema

El concepto de trayectoria queda cojo

El analyst no puede razonar causalmente

‚úÖ Comando que falta
Nuevo intent: TEMPORAL_RELATION_QUERY
{
  "intent": "TEMPORAL_RELATION_QUERY",
  "entity": "signals",
  "operation": "sequence",
  "filters": {
    "anchor_event": "CRITICAL_MONDAY"
  },
  "time": {
    "type": "window",
    "value": "pre_post"
  },
  "output": "analysis"
}


‚úîÔ∏è Esto habilita:

‚Äúantes / despu√©s‚Äù

an√°lisis causal

narrativa real, no forzada

2.3 ‚ùå Falta: consultas por ausencia de datos

Esta es muy importante y casi nadie la modela.

Preguntas reales:

‚Äú¬øQu√© controles NO se observaron?‚Äù

‚Äú¬øQu√© riesgos no tuvieron auditor√≠as?‚Äù

‚Äú¬øD√≥nde faltan observaciones?‚Äù

üî¥ Problema

El sistema solo habla de lo que existe

No puede detectar silencios peligrosos

‚úÖ Comando que falta
Nuevo operation: detect_absence
{
  "intent": "ANALYTICAL_QUERY",
  "entity": "observations",
  "operation": "detect_absence",
  "filters": {
    "risk_id": ["R01"]
  },
  "time": {
    "type": "relative",
    "value": "last_month"
  },
  "output": "analysis"
}


‚úîÔ∏è Esto es oro para seguridad operacional.

2.4 ‚ùå Falta: consultas por relaci√≥n cruzada de entidades

Hoy no puedes preguntar can√≥nicamente:

‚ÄúQu√© eventos est√°n asociados a las observaciones de R02‚Äù
‚ÄúQu√© auditor√≠as precedieron a los eventos‚Äù

üî¥ Problema

El grafo cognitivo no se explota

El analyst queda limitado

‚úÖ Comando que falta
Nuevo operation: relate
{
  "intent": "ANALYTICAL_QUERY",
  "entity": "events",
  "operation": "relate",
  "filters": {
    "related_to": {
      "entity": "observations",
      "risk_id": ["R02"]
    }
  },
  "output": "analysis"
}

2.5 ‚ùå Falta: consultas de ranking expl√≠cito

Hoy hablas de ‚Äúriesgo dominante‚Äù, pero no puedes pedir:

‚Äúmu√©strame el ranking completo‚Äù
‚Äútop 3 riesgos por presi√≥n operacional‚Äù

üî¥ Problema

El smoke fuerza narrativa

MetricsNode no se usa correctamente

‚úÖ Comando que falta
Nuevo operation: rank
{
  "intent": "OPERATIONAL_QUERY",
  "entity": "risks",
  "operation": "rank",
  "filters": {
    "metric": "operational_pressure"
  },
  "time": {
    "type": "relative",
    "value": "last_week"
  },
  "output": "raw"
}


üëâ Esto DEBE venir del MetricsNode, no del Narrative.

2.6 ‚ùå Falta: comandos de diagn√≥stico del sistema

Muy √∫til para debug y demo.

Ejemplos reales:

‚ÄúQu√© data est√° disponible‚Äù

‚ÄúQu√© semanas est√°n cargadas‚Äù

‚ÄúQu√© riesgos tienen trayectoria‚Äù

‚úÖ Comando que falta
{
  "intent": "SYSTEM_QUERY",
  "entity": "data_coverage",
  "operation": "summarize",
  "output": "summary"
}

3. Resumen: Comandos que hay que agregar
Nuevos intents

TEMPORAL_RELATION_QUERY

Nuevas operations

retrieve_by_id

sequence

detect_absence

relate

rank

Nuevos conceptos expl√≠citos

Ancla temporal (anchor_event)

Ausencia como se√±al

Relaci√≥n cruzada entre entidades

4. Impacto directo en tu problema actual

Esto explica TODO lo que viste:

‚ùå Narrative intentando ‚Äúrellenar‚Äù

‚ùå Analyst devolviendo frases gen√©ricas

‚ùå Smoke forzando tokens (‚Äúlunes‚Äù, ‚ÄúR02‚Äù)

‚ùå Confusi√≥n entre operational vs analyst

üëâ No era un bug
üëâ Era un lenguaje incompleto

5. Estado actual (importante)

Con estas extensiones:

El Operational queda blindado

El Analyst deja de improvisar

El Narrative vuelve a ser un traductor

El LLM entra limpio y gobernado

----------------

K9 Mining Safety
Canonical Cognitive Language ‚Äì v1.1
1. Prop√≥sito del Lenguaje Can√≥nico

El Lenguaje Can√≥nico K9 es el idioma interno del sistema cognitivo, utilizado por:

DataEngineNode

OperationalAnalysisNode

AnalystNode

MetricsNode

NarrativeNode

LLM (como traductor, no decisor)

Principios clave

No es lenguaje natural

No interpreta intenci√≥n humana

No inventa narrativa

Describe exactamente qu√© dato consultar y c√≥mo

Todo output debe ser trazable a datos

2. Estructura General del Comando
{
  "intent": "<INTENT_TYPE>",
  "entity": "<ENTITY_TYPE>",
  "operation": "<OPERATION_TYPE>",
  "filters": { ... },
  "time": { ... },
  "relations": { ... },
  "output": "<OUTPUT_TYPE>"
}

3. INTENTS (Tipos de intenci√≥n can√≥nica)
3.1 OPERATIONAL_QUERY

Consultas directas y factuales sobre datos sint√©ticos.

‚ÄúQu√© pas√≥‚Äù, ‚Äúcu√°ntos‚Äù, ‚Äúcu√°les‚Äù, ‚Äúlistar‚Äù, ‚Äúdetalle‚Äù

3.2 ANALYTICAL_QUERY

Interpretaci√≥n determinista basada en reglas.

Tendencias, evoluci√≥n, presi√≥n, diagn√≥stico

3.3 COMPARATIVE_QUERY

Comparaci√≥n entre modelos o fuentes.

K9 vs Proactivo, antes vs despu√©s

3.4 TEMPORAL_RELATION_QUERY

Relaciones temporales antes / despu√©s / secuencia.

Causalidad temporal

3.5 SYSTEM_QUERY

Estado del sistema y cobertura de datos.

Debug, demo, validaci√≥n

4. ENTITIES (Entidades consultables)
Entity	Descripci√≥n
observations	OCC / OPG
events	Eventos operacionales
audits	Auditor√≠as
fdo	Factores Din√°micos Operacionales
trajectories	Trayectorias de riesgo
risks	Riesgos
controls	Controles cr√≠ticos
proactive_model	Modelo proactivo
signals	Se√±ales agregadas
data_coverage	Cobertura de datos
5. OPERATIONS (Acciones)
5.1 B√°sicas
Operation	Uso
list	Listar entidades
count	Conteo
summarize	Resumen factual
retrieve_by_id	Detalle por ID
5.2 Temporales
Operation	Uso
evolution	Evoluci√≥n en el tiempo
sequence	Antes / despu√©s
window	Ventana temporal
5.3 Anal√≠ticas
Operation	Uso
rank	Ranking
detect_absence	Ausencia de datos
relate	Relaci√≥n entre entidades
explain	Explicaci√≥n determinista
6. TIME (Dimensi√≥n temporal)
"time": {
  "type": "absolute | relative | window",
  "value": "2025-01-01 | last_week | last_month | pre_post"
}

Ejemplos v√°lidos

last_week

last_4_weeks

week_01_2025

pre_post + anchor_event

7. RELATIONS (Relaciones entre entidades)
"relations": {
  "related_to": {
    "entity": "observations",
    "risk_id": ["R02"]
  }
}


Permite:

Eventos asociados a observaciones

Auditor√≠as previas a eventos

Se√±ales derivadas de FDO

8. OUTPUT TYPES
Output	Uso
raw	Datos sin interpretaci√≥n
analysis	Resultado determinista
summary	Resumen factual
trace	Evidencia detallada
9. EJEMPLOS CAN√ìNICOS (CR√çTICOS)
9.1 Conteo de observaciones (blindado)
{
  "intent": "OPERATIONAL_QUERY",
  "entity": "observations",
  "operation": "count",
  "time": {
    "type": "relative",
    "value": "last_week"
  },
  "output": "raw"
}

9.2 Se√±ales antes del lunes cr√≠tico
{
  "intent": "TEMPORAL_RELATION_QUERY",
  "entity": "signals",
  "operation": "sequence",
  "filters": {
    "anchor_event": "CRITICAL_MONDAY"
  },
  "time": {
    "type": "window",
    "value": "pre_post"
  },
  "output": "analysis"
}

9.3 Riesgos subestimados por el modelo proactivo
{
  "intent": "COMPARATIVE_QUERY",
  "entity": "risks",
  "operation": "compare",
  "filters": {
    "model": "proactive_model",
    "baseline": "K9"
  },
  "output": "analysis"
}

9.4 Detalle de un evento espec√≠fico
{
  "intent": "OPERATIONAL_QUERY",
  "entity": "events",
  "operation": "retrieve_by_id",
  "filters": {
    "event_id": ["EVT_2025_001"]
  },
  "output": "raw"
}

9.5 Ausencia de observaciones (se√±al silenciosa)
{
  "intent": "ANALYTICAL_QUERY",
  "entity": "observations",
  "operation": "detect_absence",
  "filters": {
    "risk_id": ["R01"]
  },
  "time": {
    "type": "relative",
    "value": "last_month"
  },
  "output": "analysis"
}

9.6 Ranking por presi√≥n operacional
{
  "intent": "OPERATIONAL_QUERY",
  "entity": "risks",
  "operation": "rank",
  "filters": {
    "metric": "operational_pressure"
  },
  "time": {
    "type": "relative",
    "value": "last_week"
  },
  "output": "raw"
}

9.7 Diagn√≥stico del sistema
{
  "intent": "SYSTEM_QUERY",
  "entity": "data_coverage",
  "operation": "summarize",
  "output": "summary"
}

10. Implicancias Arquitect√≥nicas (clave)
Nodo	Rol
DataEngine	Ejecuta OPERATIONAL_QUERY
OperationalAnalysis	Responde factual
Analyst	Solo ANALYTICAL / COMPARATIVE
MetricsNode	Rankings, agregados
NarrativeNode	Traduce resultados
LLM	Traduce humano ‚Üî can√≥nico
11. Estado del Sistema con v1.1

‚úÖ Operational blindado

‚úÖ Analyst no improvisa

‚úÖ Narrative deja de ‚Äúinventar‚Äù

‚úÖ Smoke debe ser can√≥nico

‚úÖ LLM entra limpio despu√©s

------------

Extensi√≥n del Lenguaje Can√≥nico K9
Ontology Query Layer ‚Äì v1.2 (extensi√≥n compatible)

Esta extensi√≥n no reemplaza v1.1
La complementa y mantiene separaci√≥n cognitiva.

1. Por qu√© esto es necesario (principio cognitivo)

Hay dos mundos distintos en K9:

Mundo	Qu√© responde
Mundo factual	Qu√© pas√≥ (datos sint√©ticos)
Mundo sem√°ntico	Qu√© es qu√© (ontolog√≠a)

Preguntas como:

‚Äú¬øCu√°les son los controles del riesgo R01?‚Äù

‚Äú¬øQu√© causas est√°n asociadas a Ca√≠da de Objetos?‚Äù

‚ÄúMu√©strame el bowtie del riesgo R02‚Äù

‚ÄúQu√© consecuencias tiene este riesgo‚Äù

üëâ NO deben ir al Operational ni al Analyst, porque:

No dependen del tiempo

No dependen de eventos

No dependen de observaciones

üëâ Son consultas ontol√≥gicas puras.

Por lo tanto, necesitamos un INTENT expl√≠cito para ontolog√≠a.

2. Nuevo INTENT: ONTOLOGY_QUERY
Definici√≥n
"intent": "ONTOLOGY_QUERY"

Prop√≥sito

Consultar estructura, relaciones y definiciones del sistema K9, incluyendo:

Riesgos

Controles

Causas

Consecuencias

Bowtie

Relaciones entre entidades

üëâ Nunca ejecuta an√°lisis ni m√©tricas
üëâ Nunca cruza con datos sint√©ticos

3. Nuevas ENTITIES ontol√≥gicas

Ampliamos el set existente:

Entity	Descripci√≥n
risk	Riesgo individual
controls	Controles cr√≠ticos
causes	Causas
consequences	Consecuencias
bowtie	Modelo bowtie
hazards	Peligros
barriers	Barreras preventivas / mitigadoras
ontology_graph	Vista estructural
4. Operaciones ontol√≥gicas permitidas
4.1 Operaciones b√°sicas
Operation	Uso
describe	Descripci√≥n de la entidad
list	Listar entidades relacionadas
relate	Relaciones entre entidades
retrieve	Obtener definici√≥n completa
4.2 Operaciones estructurales
Operation	Uso
get_controls	Controles de un riesgo
get_causes	Causas asociadas
get_consequences	Consecuencias
get_bowtie	Bowtie completo
get_barriers	Barreras por tipo
5. Ejemplos can√≥nicos de consultas ontol√≥gicas
5.1 Controles de un riesgo
{
  "intent": "ONTOLOGY_QUERY",
  "entity": "risk",
  "operation": "get_controls",
  "filters": {
    "risk_id": "R01"
  },
  "output": "raw"
}

5.2 Causas asociadas a un riesgo
{
  "intent": "ONTOLOGY_QUERY",
  "entity": "risk",
  "operation": "get_causes",
  "filters": {
    "risk_id": "R02"
  },
  "output": "raw"
}

5.3 Bowtie completo
{
  "intent": "ONTOLOGY_QUERY",
  "entity": "bowtie",
  "operation": "retrieve",
  "filters": {
    "risk_id": "R02"
  },
  "output": "raw"
}

5.4 Relaci√≥n control ‚Üí riesgo
{
  "intent": "ONTOLOGY_QUERY",
  "entity": "controls",
  "operation": "relate",
  "filters": {
    "control_id": "C_014"
  },
  "output": "raw"
}

5.5 Vista estructural del riesgo
{
  "intent": "ONTOLOGY_QUERY",
  "entity": "risk",
  "operation": "retrieve",
  "filters": {
    "risk_id": "R01"
  },
  "output": "summary"
}

6. Nodo responsable (muy importante)

Este tipo de query NO debe ir a:

‚ùå OperationalAnalysisNode

‚ùå AnalystNode

‚ùå MetricsNode

Debe ir a:

üü¢ OntologyQueryNode (nuevo o existente seg√∫n dise√±o)
Nodo	Rol
OntologyQueryNode	Acceso a ontolog√≠a (YAML / GDB / VDB)
NarrativeNode	Traducci√≥n del resultado
LLM	Traducci√≥n humano ‚Üî can√≥nico
7. C√≥mo convive con el resto del sistema
Tipo de pregunta	Nodo
‚ÄúQu√© pas√≥‚Äù	Operational
‚ÄúC√≥mo evolucion√≥‚Äù	Analyst
‚ÄúPor qu√© es importante‚Äù	Analyst
‚ÄúQu√© es este riesgo‚Äù	Ontology
‚ÄúQu√© controles tiene‚Äù	Ontology
‚ÄúMu√©strame el bowtie‚Äù	Ontology

üëâ No hay ambig√ºedad
üëâ No hay mezcla cognitiva

8. Implicaci√≥n clave para el LLM (futuro)

El LLM no decide si algo es ontolog√≠a u operacional.

√âl solo traduce:

Lenguaje humano ‚Üí Lenguaje can√≥nico

Ejemplo:

‚Äú¬øCu√°les son los controles del riesgo R01?‚Äù

‚¨áÔ∏è

{
  "intent": "ONTOLOGY_QUERY",
  "entity": "risk",
  "operation": "get_controls",
  "filters": {
    "risk_id": "R01"
  },
  "output": "raw"
}

9. Estado final del sistema con esta extensi√≥n

‚úÖ Datos sint√©ticos blindados

‚úÖ An√°lisis determinista protegido

‚úÖ Ontolog√≠a consultable expl√≠citamente

‚úÖ Sin dependencia de lenguaje natural

‚úÖ Preparado para GDB / VDB / YAML

‚úÖ Smoke can√≥nico completo


-----------------

¬øC√≥mo se le ense√±a a un LLM a traducir lenguaje humano ‚Üí lenguaje K9 (can√≥nico) sin romper el sistema cognitivo?

La respuesta corta es:
üëâ no se le ‚Äúense√±a‚Äù como a un modelo de ML,
üëâ se le instruye, acota y gobierna como int√©rprete.

Voy por partes.

1. Principio fundacional (esto aclara todo)

En K9:

El LLM NO decide qu√© hacer.
El LLM SOLO traduce.

Eso implica una regla dura:

El LLM nunca produce respuestas finales,
solo produce estructuras intermedias.

Si esto no est√° claro, todo se desordena.

2. Qu√© significa ‚Äútraducir humano ‚Üí K9‚Äù

Traducir no es ‚Äúentender sem√°nticamente todo‚Äù.
Traducir es mapear una pregunta humana a un comando v√°lido del sistema.

Ejemplo humano:

‚Äú¬øQu√© eventos pasaron la primera semana de enero?‚Äù

Eso no es una intenci√≥n libre, es una consulta estructurada:

{
  "intent": "OPERATIONAL_QUERY",
  "entity": "event",
  "operation": "list",
  "filters": {
    "date_range": {
      "from": "2025-01-01",
      "to": "2025-01-07"
    }
  }
}


üëâ El LLM no ejecuta nada, solo genera esto.

3. C√≥mo se le ense√±a eso al LLM (m√©todo real)

No es fine-tuning (por ahora).
Es prompt engineering estructural + contratos estrictos.

3.1 El LLM recibe un ROL FIJO

Ejemplo (conceptual):

You are the K9 Language Interpreter.
Your task is to translate human questions into K9 Canonical Commands.
You must NEVER answer the user directly.

Esto no es cosm√©tico:
es una instrucci√≥n de identidad funcional.

3.2 Se le entrega el Lenguaje Can√≥nico como SPEC

El LLM debe ‚Äúver‚Äù algo as√≠ (resumido):

K9_CANONICAL_LANGUAGE:
  intents:
    - OPERATIONAL_QUERY
    - ANALYST_QUERY
    - ONTOLOGY_QUERY
  entities:
    - risk
    - event
    - observation
    - audit
    - fdo
    - trajectory
  operations:
    - list
    - count
    - summarize
    - compare
  filters:
    - date_range
    - risk_id
    - week


üëâ El LLM no inventa, solo selecciona.

3.3 Se le muestran ejemplos can√≥nicos (few-shot)

Esto es clave.

Ejemplo:

Input humano

‚ÄúDame los eventos de la semana 1‚Äù

Output esperado

{
  "intent": "OPERATIONAL_QUERY",
  "entity": "event",
  "operation": "list",
  "filters": {
    "week": 1
  }
}


Con 10‚Äì20 ejemplos bien dise√±ados, el LLM aprende el mapeo.

4. Blindaje: c√≥mo evitamos que el LLM rompa el sistema

Aqu√≠ est√° lo que no hab√≠amos dicho expl√≠citamente y es cr√≠tico.

4.1 Validaci√≥n estructural obligatoria

Todo output del LLM pasa por:

JSON Schema

Validaci√≥n de enums

Validaci√≥n de campos obligatorios

Si falla ‚Üí rechazo + reintento guiado.

4.2 El LLM NO conoce los datos

El LLM:

‚ùå No ve STDE

‚ùå No ve auditor√≠as

‚ùå No ve eventos reales

Solo conoce:

El lenguaje

El contrato

Eso elimina alucinaciones.

5. Qu√© pasa despu√©s de la traducci√≥n

Pipeline real:

Usuario humano
   ‚Üì
LLM (int√©rprete)
   ‚Üì
Comando can√≥nico K9
   ‚Üì
Router
   ‚Üì
Operational / Analyst / Ontology
   ‚Üì
State estructurado
   ‚Üì
NarrativeNode
   ‚Üì
(LLM opcional para redacci√≥n)


üëâ El LLM nunca toca los datos.

------------------------------

